
I. SETUP.

What you need:

1) Student submissions.

You need a file that lists all directories containing student
submissions.  The directory examples contains six "student"
submissions, from students "correct", "failures", "infloop",
"nosubmissions", "nullpointer", and "syntax" (see directory
jam/examples/submissions). Each submission is in a folder named E2.
Therefore, you need the file (see directories.txt) with the following
contents:

jam/examples/submissions/correct/E2
jam/examples/submissions/failures/E2
jam/examples/submissions/infloop/E2
jam/examples/submissions/nosubmission/E2
jam/examples/submissions/nullpointer/E2
jam/examples/submissions/syntax/E2

2) Student information.

You need a classlist (see students.csv) in the following format:

student-id,first-name,last-name,student-number,email

TIP: if you are at UofT, you can get this list from Blackboard.

3) Group information.

If your students were working in groups and submitted one solution per
group, then you need a file that records this information. It should
be in the format (see groups.txt):

group-name,dir-name,student-id-1,student-id-2,...

Actually, even if your students were working individually, you still
need this file. In other words, we assume that students ALWAYS work in
groups. When they work individually, the group size is 1, and you have
a group per student.

TIP: If you are using MarkUs, you can download this file from your
MarkUs web inerface.

4) Name matching.

You need a file that matches submission directories with group
names. See dirs_and_names.txt for an example.

5) Your test files to be used to test each individual submission. Any
additional files you need to run individual tests.

REQUIREMENTS for the test files:

Starting with your "normal" JUnit4 test file, you create a JAM test
file as follows:

a) import edu.toronto.cs.jam.annotations.Description;

b) For each @Test method, use the following annotations:
   @Test(timeout=XXX)
   @Description(description="description of your test method")

6) Your solution (or solution stubs) to compile your tests.

II. Compile your tests.

See compile_tests.sh.

III.  Run the tests.

To run the tests, you need to modify the file config.py and place it
in the same directory as test_runner.py.

Look at the directory examples for a sample config.py file and sample
input files.


TIP: Especially if you plan to grade more than one piece of work, I
suggest creating symlinks to your submissions directory and file
config.py.

Finally,

python3 test_runner.py

If everything went well, you should have a .json file in each student
submission directory.


IV.  Aggregate the results.

python3 aggregator.py --help

For our example:
python3 aggregator.py E2 jam/examples/dirs_and_names.txt jam/examples/students.csv jam/examples/groups.txt result.json E2aggregated.json

V.  Produce templated reports.

python3 templator.py --help

For our example:
python3 templator.py E2aggregated.json txt       will produce all individual txt reports and an aggregate txt report
python3 templator.py -a E2aggregated.json html   will produce an aggregate html report
python3 templator.py -a E2aggregated.json gf     will produce an aggregate gf grades file